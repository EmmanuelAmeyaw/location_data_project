{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"weather_station_clustering\" align=\"center\"> Clustering Ghanaian households based on their expenditure patterns</h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of this project will be deployed in two formats. First, the insights found in this data will be reported in a PDF file and shared among stakeholders. The report can be found here, https://github.com/EmmanuelAmeyaw/IBM-capstone-prject\n",
    "Second, to classify new households (new data) into the existing clusters found in the dataset, we will build a keras deep learning classifier to learn and explaining the cluster assignments. The model will then be deployed on the IBM Watson Machine Learning platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make sure that the current versions of Keras and Tensorflow are matching the requirements. Indeed they do match the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:\t 2.1.5\n",
      "Expected:\t 2.1.3\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print('Current:\\t', keras.__version__)\n",
    "print('Expected:\\t 2.1.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:\t 1.8.0\n",
      "Expected:\t 1.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('Current:\\t', tf.__version__)\n",
    "print('Expected:\\t 1.5.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will train a household classifier model. First, let's import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totfood</th>\n",
       "      <th>totalch</th>\n",
       "      <th>totclth</th>\n",
       "      <th>tothous</th>\n",
       "      <th>totfurn</th>\n",
       "      <th>tothlth</th>\n",
       "      <th>tottrsp</th>\n",
       "      <th>totcmnq</th>\n",
       "      <th>totrcre</th>\n",
       "      <th>toteduc</th>\n",
       "      <th>totmisc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.187262</td>\n",
       "      <td>0.154462</td>\n",
       "      <td>0.381787</td>\n",
       "      <td>0.160858</td>\n",
       "      <td>0.205355</td>\n",
       "      <td>0.123294</td>\n",
       "      <td>0.125713</td>\n",
       "      <td>0.208678</td>\n",
       "      <td>0.144971</td>\n",
       "      <td>0.28414</td>\n",
       "      <td>0.199687</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.187262</td>\n",
       "      <td>0.154462</td>\n",
       "      <td>0.381787</td>\n",
       "      <td>0.160858</td>\n",
       "      <td>0.205355</td>\n",
       "      <td>0.123294</td>\n",
       "      <td>0.125713</td>\n",
       "      <td>0.208678</td>\n",
       "      <td>0.144971</td>\n",
       "      <td>0.28414</td>\n",
       "      <td>0.199687</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    totfood   totalch   totclth   tothous   totfurn   tothlth   tottrsp  \\\n",
       "0  0.187262  0.154462  0.381787  0.160858  0.205355  0.123294  0.125713   \n",
       "1  0.187262  0.154462  0.381787  0.160858  0.205355  0.123294  0.125713   \n",
       "\n",
       "    totcmnq   totrcre  toteduc   totmisc  label  \n",
       "0  0.208678  0.144971  0.28414  0.199687      0  \n",
       "1  0.208678  0.144971  0.28414  0.199687      0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('XX_dfl2.csv')\n",
    "df.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove noisy data points. data points with a label of -1 are noisy data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = df.label != -1\n",
    "df = df[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5626\n",
       "0    1945\n",
       "2    1281\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(df, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_set.iloc[:,0:11].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_set.iloc[:,0:11].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_set.iloc[:,11:12].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_set.iloc[:,11:12].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "totfood    float64\n",
       "totalch    float64\n",
       "totclth    float64\n",
       "tothous    float64\n",
       "totfurn    float64\n",
       "tothlth    float64\n",
       "tottrsp    float64\n",
       "totcmnq    float64\n",
       "totrcre    float64\n",
       "toteduc    float64\n",
       "totmisc    float64\n",
       "label        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors (int) to binary class matrices\n",
    "num_classes = 3\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6196 samples, validate on 2656 samples\n",
      "Epoch 1/50\n",
      "6196/6196 [==============================] - 12s 2ms/step - loss: 0.2622 - acc: 0.8686 - val_loss: 3.7643e-04 - val_acc: 1.0000\n",
      "Epoch 2/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 7.6553e-05 - acc: 1.0000 - val_loss: 6.1454e-06 - val_acc: 1.0000\n",
      "Epoch 3/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 2.0765e-06 - acc: 1.0000 - val_loss: 4.0752e-07 - val_acc: 1.0000\n",
      "Epoch 4/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 2.0759e-07 - acc: 1.0000 - val_loss: 1.1955e-07 - val_acc: 1.0000\n",
      "Epoch 5/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1929e-07 - acc: 1.0000 - val_loss: 1.1941e-07 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1923e-07 - acc: 1.0000 - val_loss: 1.1934e-07 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1928e-07 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1925e-07 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1925e-07 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1923e-07 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1923e-07 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "6196/6196 [==============================] - 13s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "6196/6196 [==============================] - 17s 3ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "6196/6196 [==============================] - 17s 3ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "6196/6196 [==============================] - 18s 3ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "6196/6196 [==============================] - 17s 3ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "6196/6196 [==============================] - 17s 3ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "6196/6196 [==============================] - 17s 3ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "6196/6196 [==============================] - 15s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "6196/6196 [==============================] - 10s 2ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "\n",
      "\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#Add layers\n",
    "model.add(Dense(500, activation='relu', input_shape=(11,)))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dense(2000, activation='softmax'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#Compile model with loss and optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer='rmsprop',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "#Train network\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "model.fit(x_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate model        \n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('\\n')\n",
    "print('Accuracy:',score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This accuracy level is not surprising since the labels of the data were generated through a deep learning autoencoder. Hence a deep learning model using similar layers are able to perfectly identify the clusters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some cleanup from the previous run\n",
    "!rm -f ker_*\n",
    "!rm -f kker_*\n",
    "!rm -f my_best_model.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are satisfied with the model above, so we will save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_function_layer_1 = 'softmax'\n",
    "opimizer = 'rmsprop'\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "save_path = \"ker_func_mnist_model_2.%s.%s.%s.h5\" % (activation_functions_layer_1,opimizer,score[1])\n",
    "model.save(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jupyterlab resources 54151768 Jul  7 06:20 ker_func_mnist_model_2.softmax.rmsprop.1.0.h5\n"
     ]
    }
   ],
   "source": [
    "ls -ltr ker_*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting the model in a .tgz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ker_func_mnist_model_2.softmax.rmsprop.1.0.h5\n"
     ]
    }
   ],
   "source": [
    "!tar -zcvf my_best_model.tgz ker_func_mnist_model_2.softmax.rmsprop.1.0.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the trained model to WML Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `watson_machine_learning_client` python library to save the trained model to WML Repository, to deploy the saved model and to make predictions using the deployed model.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting watson-machine-learning-client\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/a1/c503614455fb734b0989e8d6abaf24d0544d7370f7eb2b80ffbc99a40caf/watson_machine_learning_client-1.0.371-py3-none-any.whl (536kB)\n",
      "\u001b[K     |████████████████████████████████| 542kB 29.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lomond (from watson-machine-learning-client)\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/b1/02eebed49c754b01b17de7705caa8c4ceecfb4f926cdafc220c863584360/lomond-0.3.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: ibm-cos-sdk in /home/jupyterlab/conda/lib/python3.6/site-packages (from watson-machine-learning-client) (2.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /home/jupyterlab/conda/lib/python3.6/site-packages (from watson-machine-learning-client) (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /home/jupyterlab/conda/lib/python3.6/site-packages (from watson-machine-learning-client) (2019.6.16)\n",
      "Requirement already satisfied, skipping upgrade: requests in /home/jupyterlab/conda/lib/python3.6/site-packages (from watson-machine-learning-client) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /home/jupyterlab/conda/lib/python3.6/site-packages (from watson-machine-learning-client) (4.32.1)\n",
      "Collecting tabulate (from watson-machine-learning-client)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/fd/202954b3f0eb896c53b7b6f07390851b1fd2ca84aa95880d7ae4f434c4ac/tabulate-0.8.3.tar.gz (46kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 14.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: urllib3 in /home/jupyterlab/conda/lib/python3.6/site-packages (from watson-machine-learning-client) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /home/jupyterlab/conda/lib/python3.6/site-packages (from lomond->watson-machine-learning-client) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: ibm-cos-sdk-core==2.*,>=2.0.0 in /home/jupyterlab/conda/lib/python3.6/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.5.1)\n",
      "Requirement already satisfied, skipping upgrade: ibm-cos-sdk-s3transfer==2.*,>=2.0.0 in /home/jupyterlab/conda/lib/python3.6/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.5.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.12.0 in /home/jupyterlab/conda/lib/python3.6/site-packages (from pandas->watson-machine-learning-client) (1.15.4)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /home/jupyterlab/conda/lib/python3.6/site-packages (from pandas->watson-machine-learning-client) (2019.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /home/jupyterlab/conda/lib/python3.6/site-packages (from pandas->watson-machine-learning-client) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /home/jupyterlab/conda/lib/python3.6/site-packages (from requests->watson-machine-learning-client) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /home/jupyterlab/conda/lib/python3.6/site-packages (from requests->watson-machine-learning-client) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /home/jupyterlab/conda/lib/python3.6/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: docutils>=0.10 in /home/jupyterlab/conda/lib/python3.6/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client) (0.14)\n",
      "Building wheels for collected packages: tabulate\n",
      "  Building wheel for tabulate (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyterlab/.cache/pip/wheels/2b/67/89/414471314a2d15de625d184d8be6d38a03ae1e983dbda91e84\n",
      "Successfully built tabulate\n",
      "Installing collected packages: lomond, tabulate, watson-machine-learning-client\n",
      "Successfully installed lomond-0.3.3 tabulate-0.8.3 watson-machine-learning-client-1.0.371\n"
     ]
    }
   ],
   "source": [
    "!pip install watson-machine-learning-client --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials={\n",
    "  \"apikey\": \"JUmH8qP63ofgxBnWCQpTsaTo8p3gYVA87-QbccKvE54D\",\n",
    "  \"iam_apikey_description\": \"Auto-generated for key 17679675-ec4a-4a29-9a78-44dd993c5c83\",\n",
    "  \"iam_apikey_name\": \"wdp-writer\",\n",
    "  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n",
    "  \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/6b12f48f115b4722bbe3cf1246ff6c67::serviceid:ServiceId-dc2fd81e-909a-4dff-b157-1c662ba49aac\",\n",
    "  \"instance_id\": \"57e1ae13-3998-426b-a23b-fdd1b4d89ede\",\n",
    "  \"password\": \"a316ecaa-8d75-4b0d-93b5-6805b568dabe\",\n",
    "  \"url\": \"https://eu-gb.ml.cloud.ibm.com\",\n",
    "  \"username\": \"17679675-ec4a-4a29-9a78-44dd993c5c83\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_props = {client.repository.ModelMetaNames.AUTHOR_NAME: \"Emmanuel Ameyaw\", \n",
    "               client.repository.ModelMetaNames.AUTHOR_EMAIL: \"ameyawemmanuel@rocketmail.com\", \n",
    "               client.repository.ModelMetaNames.NAME: \"KK3_clt_keras_household_clustering_ghana\",\n",
    "               client.repository.ModelMetaNames.FRAMEWORK_NAME: \"tensorflow\",\n",
    "               client.repository.ModelMetaNames.FRAMEWORK_VERSION: \"1.5\" ,\n",
    "               client.repository.ModelMetaNames.FRAMEWORK_LIBRARIES: [{\"name\": \"keras\", \"version\": \"2.1.3\"}]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-07 06:41:22,010 - watson_machine_learning_client.metanames - WARNING - 'AUTHOR_EMAIL' meta prop is deprecated. It will be ignored.\n"
     ]
    }
   ],
   "source": [
    "published_model = client.repository.store_model(model=\"my_best_model.tgz\", meta_props=model_props) #my_best_model.tgz already saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_model_uid = client.repository.get_model_uid(published_model)\n",
    "model_details = client.repository.get_details(published_model_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy the Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----  ----  ----  -----  -------  ---------  -------------\n",
      "GUID  NAME  TYPE  STATE  CREATED  FRAMEWORK  ARTIFACT TYPE\n",
      "----  ----  ----  -----  -------  ---------  -------------\n"
     ]
    }
   ],
   "source": [
    "client.deployments.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep your environment clean, just delete all deployments from previous runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.deployments.delete(\"PASTE_YOUR_GUID_HERE_IF_APPLICABLE = \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "Synchronous deployment creation for uid: 'aa4cb69a-0816-4a5e-bd46-48e46581c5be' started\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "\n",
      "INITIALIZING\n",
      "DEPLOY_IN_PROGRESS\n",
      "DEPLOY_SUCCESS\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_uid='c5c96e45-964f-474b-a931-9442033f7c9e'\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "created_deployment = client.deployments.create(published_model_uid, name=\"k1_keras_household_clustering_clt1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://eu-gb.ml.cloud.ibm.com/v3/wml_instances/57e1ae13-3998-426b-a23b-fdd1b4d89ede/deployments/c5c96e45-964f-474b-a931-9442033f7c9e/online\n"
     ]
    }
   ],
   "source": [
    "#scoring_endpoint = client.deployments.get_scoring_url(created_deployment)\n",
    "# scoring of provided questions and aswers data\n",
    "scoring_endpoint = created_deployment['entity']['scoring_url']\n",
    "print(scoring_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXAMPLE 1: Get some input data AND predict its label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose x_test[3] which we know is a middle class household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18726212, 0.15446213, 0.38178715, 0.16085844, 0.20535469, 0.12329403, 0.12571345, 0.20867807, 0.14497079, 0.28414047, 0.1996867]\n",
      "[1. 0. 0.] IS MIDDLE CLASS\n"
     ]
    }
   ],
   "source": [
    "print(x_test[3].tolist()) # x input\n",
    "print(y_test[3], 'IS MIDDLE CLASS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's predict it with our deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_score_1 = x_test[3].tolist()\n",
    "#print('The answer should be: ',np.argmax(y_test[23]))\n",
    "scoring_payload = {'values': [x_score_1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': ['prediction', 'prediction_classes', 'probability'],\n",
       " 'values': [[[1.0, 5.5607145554859017e-08, 3.4113877944719206e-08],\n",
       "   0,\n",
       "   [1.0, 5.5607145554859017e-08, 3.4113877944719206e-08]]]}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = client.deployments.score(scoring_endpoint, scoring_payload)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster0: MIDDLE CLASS\n"
     ]
    }
   ],
   "source": [
    "xx = predictions['values'][0][2]\n",
    "xxr = [round(x) for x in xx]\n",
    "s = xxr\n",
    "a = np.array([1, 0, 0])\n",
    "b = np.array([0, 1, 0])\n",
    "x = (s == a).all() \n",
    "y = (s == b).all() \n",
    "if x:\n",
    "  print('cluster0: MIDDLE CLASS')\n",
    "elif y: \n",
    "  print('cluster1: LOWER CLASS')\n",
    "else:\n",
    "  print('cluster2: UPPER CLASS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah!! It works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster1: LOWER CLASS\n"
     ]
    }
   ],
   "source": [
    "x_score_1 = x_test[1].tolist()\n",
    "#print('The answer should be: ',np.argmax(y_test[23]))\n",
    "scoring_payload = {'values': [x_score_1]}\n",
    "predictions = client.deployments.score(scoring_endpoint, scoring_payload)\n",
    "predictions\n",
    "\n",
    "xx = predictions['values'][0][2]\n",
    "xxr = [round(x) for x in xx]\n",
    "s = xxr\n",
    "#s = y_test[3]\n",
    "a = np.array([1, 0, 0])\n",
    "b = np.array([0, 1, 0])\n",
    "x = (s == a).all() \n",
    "y = (s == b).all() \n",
    "if x:\n",
    "  print('cluster0: MIDDLE CLASS')\n",
    "elif y: \n",
    "  print('cluster1: LOWER CLASS')\n",
    "else:\n",
    "  print('cluster2: UPPER CLASS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this deployed model, we can get new data, normalize the data and predict the class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
